---
title: "Riscos de privacidade ao utilizar-se das IAs Genéricas e como se proteger para evitar surpresas"
description: "Fique atento aos termos de uso das IAs das Big Techs e evite que seus dados mais importantes, estratégicos e sensíveis sejam disponibilizados."
date: "2025-04-25"
image: "seguranca_ia.png"
author: "Wilson Neto"
---

Enquanto advogados, somos acostumados a analisar termos contratuais e normas escritas. Com as IAs Genéricas (aquelas  das Big Techs - ChetGPT, Copilot, Grok, Gemini - não produzidas por Legaltechs com escopo específico para a advocacia) é necessário ter um cuidado adicional: analisar os Termos de Uso e Privacidade.

## Entendendo que quaisquer documentos submetidos a uma IA são enviados a um servidor fora da rede do escritório do advogado

Ao utilizar IA Generativa, o advogado precisa entender o fluxo das informações na cadeia tecnológica e o grau de interferência que isso tem nos aspectos de privacidade e segurança da informação.

Considerando que o poder computacional necessário para executar tarefas em LLMs é gigantesco, e que, além disso, o conhecimento técnico para tal é bastante específico e oneroso, dificilmente um escritório de advocacia irá implementar ferramentas próprias dentro de uma infraestrutura tecnológica própria, com um modelo de linguagem proprietário.

Isso significa que, caso seu escritório não fabrique sua própria tecnologia, invariavelmente, alguma informação na interação com sistemas computacionais será enviada para a infraestrutura tecnológica que integra a aplicação que o advogado está a utilizar e pertence a uma outra parte da cadeia econômica.

Para ilustrar:
1. Se você consultar um número de processo, esse número será fornecido e entrará no ambiente/domínio daquele prestador de serviço de consulta.
2. Se você busca alguma jurisprudência, aquelas (e apenas aquelas) palavras da sua consulta transitarão para o sistema tecnológico da outra parte.

Os exemplos acima não oferecem riscos. Porém, com o advento da IA Generativa, advogados passaram a fornecer modelos de peças, fatos de casos reais, contratos e outros documentos com informações sensíveis a sistemas administrados por terceiros.

>Responda: qual a chance de algum advogado da sua equipe ter submetido algum documento que não deveria a um LLM?

>Responda: no seu escritório já utilizaram ferramentas online para concatenar arquivos PDF? Se sim essas ferramentas tiveram acesso pleno àqueles documentos submetidos, inclusive a informações porventura existentes.

>Resolvi escrever este artigo na ideia de alertar para algo que muitas vezes é menosprezado: entender os ternos de uso e, até, possibilitar consentimento contrário ao uso de dadps para treinamento de modelos.

Assim, abaixo, segue links das políticas de privacidade das principais aplicações gerais de LLM.

**OBSERVAÇÃO IMPORTANTE: Os links fornecidos podem deixar de existir ou ter o conteúdo alterado. Além disso, se o seu escritório usar algumas dessas ferramentas é interessante procurar saber as regras que são aplicadas a sua conta/assinatura.**

**OBSERVAÇÃO IMPORTANTE: As políticas aqui abaixo apresentadas diferem das políticas das políticas de outras ferramentas que possam utilizar-se dos mesmos modelos de IA. Pois, são contratos diferentes. Uma empresa que usam um dos LLMs de terceiros possui um contrato específico diferente de um usuário do aplicativo Gemini puro e simples.**

### ChatGPT:
>https://openai.com/pt-BR/policies/terms-of-use/

Ao utilizar o ChatGPT existe a opção de não usar os dados para treinar/aprimorar os modelos de IA da OpenAI.

![Termos de Uso ChatGPT](/images/articles/chatgpt.png "Termos de Uso ChatGPT") 

### Gemini: 
>https://support.google.com/gemini/answer/13594961?authuser=1&authuser=1&visit_id=638685048770383420-1737315853&p=privacy_help&rd=1#your_data

No caso do Gemini, os termos são explícitos ao alertar que informações confidenciais não devam ser fornecidas nas interações com o aplicativo do Gemini

![Termos de Uso Gemini](/images/articles/gemini.png "Termos de Uso Gemini") 

### Copilot:
> https://learn.microsoft.com/en-us/power-platform/faqs-copilot-data-security-privacy

Copilot alega não usar os dados para treinar os próprios modelos. Logo é interessante procurar dentre as configurações do usuário, qual opção está selecionada

![Termos de Uso Copilot](/images/articles/copilot.png "Termos de Uso Copilot") 

### Grok
>https://x.ai/legal/privacy-policy

Grok informa que dados pessoais não devem ser inputados e que podem ser usados por eles ou por terceiros contratados

![Termos de Uso Grok](/images/articles/grok.png "Termos de Uso Grok") 


## Conclusão

Utilizar IAs Genéricas pode ser útil se, antes de mais nada, riscos dejam mitigados. Tão logo, é de supra importância:
1. Evitar o trânsito de documentos com alguma espécie de proteção antes do devido tratamento
2. Conhecer os termos de uso e privacidade das ferramentas e configurar, quando disponível, consigurações de consentimento.
3. Para o caso de escritórios, instituir uma política interna com treinamento e auditoria periódica, de preferência.

É importante também analisar se o uso da IA faz sentido ou se não é apenas uma forma diferente de fazer o mesmo trabalho. Com a onda das IAs jurídicas, muitos produtos são criados, mas alguns podem não trazer ganhos reais. Analise, testes todos que puder e escolha aqueles que realmente entregam valor.